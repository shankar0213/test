# Import required libraries
import pandas as pd
import numpy as np
import re

my_variable_1 = 'Yes' #'row_col_count' 'No'
my_variable_2 = [] #'columntodrop', [])
my_variable_3 = [] #'columntoretain', [])

# DataFrames
df1 = {"ID": [1, 2, 3, 4, 5], "Name": ["Alice", "Bob", "Charlie", "David", "Eve"], "Age": [25, 30, 35, 40, 45], "Score": [90, 85, 88, 92, 87]}
df2 = {"ID": [1, 2, 3, 4, 5], "Name": ["Alice", "Bob", "Charlie", "David", "Eve"], "Age": [25, 30, 35, 40, 45], "Score": [90, 85, 88, 92, 87]}

DFDSS = pd.DataFrame(df1) #test
DFPAX = pd.DataFrame(df2) #actual


# Data Cleaning Function
def data_cleaning(dataframe):
    dataframe.columns = [re.sub('[^a-zA-Z0-9]', '', names.lower()) for names in dataframe.columns.values]
    dataframe.fillna('no_value', inplace=True)
    dataframe = dataframe.astype("str")
    dataframe.sort_index(axis=1, inplace=True)
    dataframe.sort_values(by=list(dataframe.columns), inplace=True)
    dataframe.reset_index(inplace=True, drop=True)
    return dataframe

# Column Identification Function
def column_identification(df, variable):
    df_cols_to_drop = []
    for i in df.columns:
        k = re.sub('[^a-zA-Z0-9]', '', i.lower())
        for j in variable:
            j = re.sub('[^a-zA-Z0-9]', '', j.lower())
            if k == j:
                df_cols_to_drop.append(i)
    return df_cols_to_drop

# Drop specified columns
if len(my_variable_2) > 0:
    dfdss_cols_to_drop = column_identification(DFDSS, my_variable_2)
    dfpax_cols_to_drop = column_identification(DFPAX, my_variable_2)

    DFDSS = DFDSS.drop(dfdss_cols_to_drop, axis=1)
    DFPAX = DFPAX.drop(dfpax_cols_to_drop, axis=1)

# Clean data
DFDSS = data_cleaning(DFDSS)
DFPAX = data_cleaning(DFPAX)

# Normalize column names to lowercase and alphanumeric
my_variable_3 = [re.sub('[^a-zA-Z0-9]', '', names.lower()) for names in my_variable_3]

# Perform row and column count validation
if my_variable_1 == 'Yes':
    if DFDSS.shape == DFPAX.shape and (DFPAX.columns == DFDSS.columns).sum() == DFPAX.shape[1]:
        if DFDSS.equals(DFPAX) == True:
            # If data is identical            
            result_df = pd.DataFrame({'Result': ['Both the datasets are the same.']})
            print(result_df)
        else:
            # Data mismatch detected
            temp = pd.DataFrame(DFDSS == DFPAX)
            df1 = temp[~temp.all(axis=1)]
            
            for i in df1.columns:
                if len(df1.index[df1[i] == False]) > 0:
                    error_df = DFDSS.iloc[df1.index[df1[i] == False]].loc[:,i:]
                    actual_df = DFPAX.iloc[df1.index[df1[i] == False]].loc[:,i:]

                    if len(my_variable_3) > 0:
                        retained_column = pd.DataFrame (DFDSS.iloc[df1.index[df1[i] == False]])[my_variable_3[0]]
                        
                    break

            new_column_name = actual_df.columns[0]
            error_df.insert(1, new_column_name +'_test', actual_df[new_column_name])

            if len(my_variable_3) > 0:
                error_df.insert(0, my_variable_3[0]+ ' (primarykey)', retained_column)

            result_df = error_df
            print(result_df)
    else:
        # Shape or column mismatch
        mismatch_df = pd.DataFrame()
        missing_paxata_col = []
        missing_dataiku_col = []

        if DFDSS.shape != DFPAX.shape:
            df_op = pd.DataFrame({'Result': ['There is a mismatch in actual, test row and column counts.'],'test Row/Column count': [DFDSS.shape],'actual Row/Column count': [DFPAX.shape]  })
            mismatch_df = mismatch_df._append(df_op)

        elif (DFPAX.columns == DFDSS.columns).sum() != DFPAX.shape[1] :
            for i in DFPAX.columns:
                if i not in DFDSS.columns:
                    missing_paxata_col.append(i)

            for j in DFDSS.columns:
                if j not in DFPAX. columns:
                    missing_dataiku_col.append(j)

            df_op2 = pd.DataFrame({'Result': ['There is mismatch in actual, test column names. '], 'Missing actual columns': [missing_paxata_col],'missing test columns':[missing_dataiku_col] })
            mismatch_df = mismatch_df._append (df_op2)

        
        result_df = mismatch_df
        print(result_df)

else:
    print("------------")
    if DFDSS.equals(DFPAX) == True:
        df = pd.DataFrame({'Result': ['Both the tables are same' ]})
        result_df = df # Compute a Pandas dataframe to write into OUTPUT DATASET NAME
        

    else:
        temp = pd.DataFrame(DFDSS == DFPAX)
        df1 = temp[~temp.a11(axis=1)]
        for i in df1.columns:
            if len(df1.index[df1[i] == False]) > 0:
                error_df = DFDSS.iloc[df1.index[df1[i] == False]].loc[:, i:]
                actual_df = DFPAX.iloc[df1.index[df1[i] == False]].loc[:, i:]

                if len(my_variable_3) > 0:
                    retained_column = pd.DataFrame(DFDSS.iloc[df1.index[df1[i] == False]]) [my_variable_3[0]]

                break
        new_column_name = actual_df.columns[0]
        error_df.insert (1, new_column_name+ '_test', actual_df[new_column_name])

        if len(my_variable_3) > 0:
            error_df.insert(0, my_variable_3[0]+ ' (primarykey)', retained_column)

        result_df = error_df





--------------
py 11

PS C:\Users\bankid\Music> venv\Scripts\python.exe -c "import platform; print(platform.python_version()); print(platform.architecture())"


PS C:\Users\bankid\Music> py -3.11 -m venv venv
   
PS C:\Users\bankid\Music> venv\Scripts\pip.exe install pandas --trusted-host pypi.org --trusted-host files.pythonhosted.org --trusted-host pypi.python.org
PS C:\Users\bankid\Music> venv\Scripts\python.exe test1.py

